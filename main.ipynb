{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi3xlHXe1BNHJU0aCmkkpe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoelYanotka/text-summary-to-speech/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0Xe8yUMte19"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers sentencepiece datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "JGvNmUVP1ouM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "id": "WO_eyQw5weI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "import wikipedia\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def summarize_page(wiki_title):\n",
        "    '''\n",
        "    Retrieves a Wikipedia page with the title given in the input, and extracts\n",
        "    its sections and paragraphs. Then, it generates summaries of the paragraphs.\n",
        "    Parameters:\n",
        "        wiki_title: a string with the title of a Wikipedia page.\n",
        "    Output:\n",
        "        A list of strings with summaries of the sections of the Wikipedia page.\n",
        "    '''\n",
        "    # Get a Wikipedia page by its title\n",
        "    wiki = wikipedia.page(wiki_title)\n",
        "\n",
        "    # Get a Wikipedia page by its url and make a soup\n",
        "    source = urlopen(wiki.url).read()\n",
        "    soup = BeautifulSoup(source,'lxml')\n",
        "\n",
        "    # page will contain the list of sections in the page, as delimited by html headlines\n",
        "    # Add a list with the page title as the first element and the summary as the second\n",
        "    page = [[soup.find('h1').get_text(), wiki.summary]]\n",
        "\n",
        "    for header in soup.find_all(['h2', 'h3']):\n",
        "        header_name = header.get_text().replace('[edit]', '')\n",
        "        if header.get_text() == 'Contents':\n",
        "            continue\n",
        "        if 'References' in header.get_text():\n",
        "            break\n",
        "        # Every element in the section list will be a list with the name of the\n",
        "        # headline as the first element and the paragraphs as the next elements\n",
        "        section = [header_name]\n",
        "        for elem in header.next_siblings:\n",
        "            # Stop at next header\n",
        "            if elem.name and elem.name.startswith('h'):\n",
        "                break\n",
        "            if elem.name == 'p':\n",
        "                # re.sub eliminate references\n",
        "                paragraph = re.sub(r'\\[.*?\\]+', '', elem.get_text())\\\n",
        "                    .replace('\\n', '')\\\n",
        "                    .replace(u'\\xa0', ' ')\n",
        "                section.append(paragraph)\n",
        "        page.append(section)\n",
        "\n",
        "    summaries = []\n",
        "    for i, section in enumerate(page):\n",
        "        if len(section) > 1:\n",
        "            for j, paragraph in enumerate(section[1:]):\n",
        "                lenght = len(paragraph.split())\n",
        "                summary = summarizer(paragraph,\n",
        "                                     max_length=lenght,\n",
        "                                     min_length=2,\n",
        "                                     do_sample=False)\n",
        "                summaries.append(summary[0]['summary_text'])\n",
        "                print(f'\\rSection: {i+1}/{len(page)}\\tParagraph: {j+1} / {len(section)}', end='')\n",
        "    print('\\r')\n",
        "    return summaries"
      ],
      "metadata": {
        "id": "VPgzNRjsRJOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_title = 'Sceloporus_virgatus'\n",
        "\n",
        "summarized_text = summarize_page(wiki_title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ0f7w_pSEhk",
        "outputId": "c298cebe-54fd-465a-f832-d3bde5022368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Section: 12/12\tParagraph: 1 / 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the model does not convert numerical characters and abbreviations into speech, the following steps are required in order for the model to be able to pronounce numbers and measures correctly."
      ],
      "metadata": {
        "id": "OCuWsRqdLVHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import num2words\n",
        "\n",
        "def parse_numbers(text):\n",
        "    '''\n",
        "    Takes a string text as input, and returns a modified version of the input\n",
        "    string where the numbers in the text have been converted to their textual\n",
        "    form and measure abbreviations have been replaced for their full name.\n",
        "    '''\n",
        "    # Common measure abbreviations to replace for its full name\n",
        "    measures = {\n",
        "    \"mm\": \"milimeters\",\n",
        "    \"cm\": \"centimeters\",\n",
        "    \"m\": \"meters\",\n",
        "    \"km\": \"kilometers\",\n",
        "    \"mg\": \"milligrams\",\n",
        "    \"g\": \"grams\",\n",
        "    \"kg\": \"kilograms\",\n",
        "    \"ml\": \"milliters\",\n",
        "    \"l\": \"liters\",\n",
        "    \"L\": \"liters\",\n",
        "    \"in\": \"inches\",\n",
        "    \"ft\": \"feet\",\n",
        "    \"yd\": \"yards\",\n",
        "    \"mi\": \"miles\",\n",
        "    \"oz\": \"ounces\",\n",
        "    \"lb\": \"pounds\",\n",
        "    \"gal\": \"gallons\"\n",
        "}\n",
        "    \n",
        "    # Find numbers folowed by any of the previous measure abbreviations and\n",
        "    # replace the abbreviation for the full name\n",
        "    pattern = r'(\\d+)\\s*(' + '|'.join(measures.keys()) + r')\\b'\n",
        "    text = re.sub(pattern, lambda m: m.group(1) + ' ' + measures[m.group(2)], text)\n",
        "\n",
        "    # Eliminate the leading zeroes in a decimal number\n",
        "    text = re.sub(r\"(\\.\\d*?[1-9])0+\\b\", r\"\\1\", text)\n",
        "\n",
        "    # Find the numbers with comma separators and deletes the comma\n",
        "    matches = re.findall(r\"(\\d+,\\d+)\", text)\n",
        "    for match in matches:\n",
        "        text = text.replace(match, match.replace(\",\", \"\"))\n",
        "\n",
        "    # Find the decimal numbers and replaces the dot character for the word \"point\"\n",
        "    matches = re.findall(r\"(\\d+.\\d+)\", text)\n",
        "    for match in matches:\n",
        "        text = text.replace(match, match.replace(\".\", \" point \"))\n",
        "\n",
        "    # Replace numbers for words\n",
        "    text = re.sub(r\"(\\d+)\", lambda x: num2words.num2words(int(x.group(0))), text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "sGMJolR3Ih2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarized_text = [parse_numbers(line) for line in summarized_text]"
      ],
      "metadata": {
        "id": "AlXOdWyFU_A-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the text is ready to be converted into audio.\n",
        "Due to the fact that the text-to-speech model supports up to 600 words, it is neccesary to create many audio files and then combine them to create the final product."
      ],
      "metadata": {
        "id": "fiWkw3FMU7li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "import soundfile as sf\n",
        "\n",
        "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
        "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
        "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
        "\n",
        "def text2audio(text, output_name='output.wav', processor=processor, model=model, vocoder=vocoder):\n",
        "    '''\n",
        "    Converts a given text into an audio file. The function uses a\n",
        "    text-to-speech model to synthesize speech and a vocoder to convert the\n",
        "    generated speech into an audio waveform.\n",
        "    '''\n",
        "    inputs = processor(text=text, return_tensors=\"pt\")\n",
        "    # load xvector containing speaker's voice characteristics from a dataset\n",
        "    embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
        "    speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
        "\n",
        "    speech = model.generate_speech(inputs[\"input_ids\"],\n",
        "                                   speaker_embeddings,\n",
        "                                   vocoder=vocoder)\n",
        "    sf.write(output_name, speech.numpy(), samplerate=16000)"
      ],
      "metadata": {
        "id": "nTUcFpJix2q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wave\n",
        "\n",
        "def merge_audio(list_of_text):\n",
        "    '''\n",
        "    Takes a list of text strings as input and outputs a merged audio file\n",
        "    containing the spoken versions of the text.\n",
        "    Parameters:\n",
        "        list_of_text (List[str]): A list of text strings to be converted to\n",
        "        speech and merged together.\n",
        "    Return:\n",
        "        None. The merged audio file is saved to disk.\n",
        "    '''\n",
        "    for i, line in enumerate(list_of_text):\n",
        "        text2audio(text=line, output_name=f'tmp_output_{i:03d}.wav')\n",
        "\n",
        "    infiles = [f for f in os.listdir() if f.startswith('tmp_output_')]\n",
        "    infiles.sort()\n",
        "    outfile = \"output.wav\"\n",
        "\n",
        "    data= []\n",
        "    for infile in infiles:\n",
        "        w = wave.open(infile, 'rb')\n",
        "        data.append([w.getparams(), w.readframes(w.getnframes())])\n",
        "        w.close()\n",
        "        \n",
        "    output = wave.open(outfile, 'wb')\n",
        "    output.setparams(data[0][0])\n",
        "    for i in range(len(data)):\n",
        "        output.writeframes(data[i][1])\n",
        "    output.close()\n",
        "\n",
        "    for f in infiles:\n",
        "        os.remove(f)"
      ],
      "metadata": {
        "id": "PgyJzvTDfNDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_audio(summarized_text)"
      ],
      "metadata": {
        "id": "N12ctVt86C3L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}